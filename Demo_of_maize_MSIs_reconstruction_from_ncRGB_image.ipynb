{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Demo_of_maize_MSIs_reconstruction_from_ncRGB_image.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"oFWHFnJO4i3o"},"source":["#!pip install --no-cache-dir -I pillow\n","!pip install hdf5storage\n","#!pip install http://download.pytorch.org/whl/cu92/torch-1.6.0-cp36-cp36m-linux_x86_64.whl\n","#!pip install torch\n","!pip3 install torchvision\n","#!git clone https://github.com/lanpa/tensorboardX && cd tensorboardX && python setup.py install\n","!pip install tensorboardX\n","!pip install --pre torch -f  https://download.pytorch.org/whl/nightly/cu101/torch-1.7.0.dev20200626%2Bcu101-cp36-cp36m-linux_x86_64.whl\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kVdWVJYaR_kD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SuO41DNu4dBG"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/\")\n","path=os.getcwd() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4WDJqACQDAL6"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCihDbmvy1-U","executionInfo":{"status":"ok","timestamp":1631678064746,"user_tz":-540,"elapsed":2782,"user":{"displayName":"San Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09693064954695030711"}}},"source":["### \n","from __future__ import division\n","from scipy import interpolate\n","import random\n","import os\n","import os.path\n","import h5py\n","import cv2\n","import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import PIL\n","\n","import scipy.io\n","import matplotlib\n","matplotlib.use('Agg')\n","from matplotlib.backends.backend_agg import FigureCanvasAgg\n","from matplotlib.figure import Figure\n","\n","import torchvision.utils as utils\n","from tensorboardX import SummaryWriter\n","###\n","import torch\n","import torch.nn as nn\n","import argparse\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","import torch.utils.data as udata\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torchvision.utils as utils\n","import time\n","import scipy.io as sio\n","import logging\n","import hdf5storage\n","import datetime\n","from math import sqrt\n","%matplotlib inline\n","import scipy.io as spio\n","from scipy.interpolate import PchipInterpolator\n","from bisect import bisect\n","from google.colab import output\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","from mpl_toolkits.mplot3d import Axes3D\n","from matplotlib.pylab import cm\n","\n","###\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value.\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def save_checkpoint_sp(model_path, epoch, iteration, model, optimizer, evaluation):\n","    \"\"\"Save the checkpoint.\"\"\"\n","    state = {\n","            'epoch': epoch,\n","            'iter': iteration,\n","            'state_dict': model.state_dict(),\n","            'optimizer' : optimizer.state_dict(),\n","            }\n","    torch.save(state, os.path.join(model_path, 'MSIsRecon_{}.pkl'.format(evaluation)))\n","\n","def plot_spectrum_msi(real, fake, epoch, i):\n","    x =np.linspace(400, 900, 5, endpoint=True) # the wavebands of the hyperspectral image\n","    fig = Figure()\n","    canvas = FigureCanvasAgg(fig)\n","    ax = fig.gca()\n","    #ax.set_ylim(0, 1)\n","    plot_real,  = ax.plot(x, real, 'ko-')\n","    plot_fake,  = ax.plot(x, fake, 'r.-')\n","    fig.legend((plot_real,plot_fake), ('real', 'fake'))\n","    canvas.draw()\n","    fig.savefig(os.path.join(iteration_path, \"{}_test_{}.png\".format(epoch,i)))\n","    I = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n","    I = I.reshape(canvas.get_width_height()[::-1]+(3,))\n","    I = np.transpose(I, [2,0,1])\n","    return np.float32(I)\n","\n","\n","def plot_spectrum_3(real, x_real, fake, epoch, i):\n","    x =np.linspace(400, 900, 3, endpoint=True) # the wavebands of the hyperspectral image\n","    fig = Figure()\n","    canvas = FigureCanvasAgg(fig)\n","    ax = fig.gca()\n","    #ax.set_ylim(0, 1)\n","    plot_real,  = ax.plot(x, real, 'ko-')\n","    plot_x_real,  = ax.plot(x, x_real, 'g.-')\n","    plot_fake,  = ax.plot(x, fake, 'r.-')\n","    fig.legend((plot_real,plot_x_real,plot_fake), ('target', \"original\", 'fake'))\n","    canvas.draw()\n","    fig.savefig(os.path.join(iteration_path, \"{}_test_{}.png\".format(epoch,i)))\n","    I = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n","    I = I.reshape(canvas.get_width_height()[::-1]+(3,))\n","    I = np.transpose(I, [2,0,1])\n","    return np.float32(I)\n","\n","def plotwithcolorbar(img, title=None, figsize=(10,10)):\n","    ''' Plot an image with a colorbar '''\n","    vmin = np.min(img)\n","    vmax = np.max(img)\n","    hh = img.shape[0]\n","    hw = img.shape[1]\n","    fig, axis = plt.subplots(1, 1, figsize=figsize)\n","    rad2 = axis.imshow(img, vmin=vmin, vmax=vmax)\n","    axis.set_title(title)\n","    divider = make_axes_locatable(axis)\n","    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.05)\n","    fig.colorbar(rad2, cax=cax)\n","    circle_b = plt.Circle((int(hw/2), int(hh/2)), 5, color='b', fill=False)\n","    axis.add_artist(circle_b)\n","    plt.close(fig)\n","    return fig, axis\n","\n","def initialize_logger(file_dir):\n","    \"\"\"Print the results in the log file.\"\"\"\n","    logger = logging.getLogger()\n","    fhandler = logging.FileHandler(filename=file_dir, mode='a')\n","    formatter = logging.Formatter('%(asctime)s - %(message)s',\"%Y-%m-%d %H:%M:%S\")\n","    fhandler.setFormatter(formatter)\n","    logger.addHandler(fhandler)\n","    logger.setLevel(logging.INFO)\n","    return logger\n","\n","\n","def mrae_loss(im_true, im_fake):\n","    error = torch.abs(im_fake-im_true)/im_true\n","    rrmse = torch.mean(error.reshape(-1))\n","    return rrmse\n","\n","def sid_loss(im_true, im_fake):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    denom1 = torch.sqrt( torch.sum( torch.pow(im_true,2), dim=1))\n","    denom2 = torch.sqrt( torch.sum( torch.pow(im_fake,2), dim=1))\n","    #\n","    unit_t = torch.div(im_true, denom1.unsqueeze(1))\n","    uint_f = torch.div(im_fake, denom2.unsqueeze(1))\n","    #\n","    sid = ((unit_t - uint_f)* (unit_t.log() - uint_f.log())).sum() / (N*H*W)\n","    return sid\n","\n","######\n","path=os.getcwd() \n","\n","def normalize(data):\n","    data_nl = data/np.amax(data)\n","    return data_nl\n","##\n","def gen_random_scale(img, base=4.5, rnd=3):\n","    np.random.seed(rnd)\n","    scale = base**(np.random.rand(1,1, img.shape[2],img.shape[3])-0.5)*2    \n","    return img*scale\n","##\n","def gen_random_scale_n(img, rnd=3):\n","    np.random.seed(rnd)\n","    scale = np.random.uniform(0.1, 1.91, (1,1, img.shape[2],img.shape[3]))   \n","    return img*scale\n","##\n","def data_process_list_n(path=path):\n","    NO_ = 1\n","    hyper_f = os.path.join(path,'Maize2018_ortho_msi_cropped_04052021')\n","    sub_h5_fd = next(os.walk(hyper_f))[1]\n","    sub_h5_fd.sort()\n","    #\n","    #rgb_f = hyper_f.replace(\"h5\", \"rgb\")\n","    rgb_f = os.path.join(path,'Maize2018_ortho_rgb_cropped_04052021')\n","    sub_rgb_fd = next(os.walk(rgb_f))[1]\n","    sub_rgb_fd.sort()\n","\n","    for sf in range(len(sub_h5_fd)):\n","        id_n = sub_h5_fd[sf].split(\"_\")[2][4:]\n","        #\n","        filenames_hyper = glob.glob(os.path.join(hyper_f,sub_h5_fd[sf],'*.h5'))\n","        filenames_rgb = glob.glob(os.path.join(rgb_f, sub_rgb_fd[sf].replace(\"h5\", \"rgb\"),'*.png'))\n","        filenames_hyper.sort()\n","        print(filenames_hyper)\n","        filenames_rgb.sort()\n","        print(filenames_rgb)\n","        h5f = h5py.File('train_040521_maize_NatColor_final_{}.h5'.format(id_n), 'w')  ## the file concatenated hsi and rgb in one file\n","        \n","        for i in range(len(filenames_hyper)):\n","            print(\"\\n\")\n","            print(filenames_hyper[i], filenames_rgb[i])\n","            # load hyperspectral image\n","            mat =  h5py.File(filenames_hyper[i],'r')\n","            hyper = np.float32(np.array(mat['img']))\n","            print((\"hyper_shape\",hyper.shape))\n","            hyper = np.transpose(hyper, [2,0,1])#/32768.0 # because it 32768.0 was divided already before cropping into 512x512 squares\n","\n","            print(\"hyper_test_max\", np.amax(hyper))\n","            print(\"hyper_test_min\",np.amin(hyper))\n","            mat.close()\n","            # load rgb image\n","            rgb =  cv2.imread(filenames_rgb[i])\n","            rgb=cv2.cvtColor(rgb, cv2.COLOR_BGR2RGB)\n","\n","            rgb = np.float32(np.transpose(rgb, [2,0,1])/255.0) # change to 0-1 range\n","\n","            print(\"rgb_test_max\", np.amax(np.float32(rgb)))\n","            print(\"rgb_test_min\", np.amin(np.float32(rgb)))\n","\n","            data = np.concatenate((hyper,rgb), 0)\n","            h5f.create_dataset(str(NO_), data=data)\n","            NO_ += 1\n","        h5f.close()\n","        print(\"NO. of samples: {}\".format(NO_-1))\n","##\n","class HyperDataset_list_maize_RGB(udata.Dataset):\n","    def __init__(self, crop_size=64):\n","        self.crop_size = crop_size\n","        xx = [\"train_040521_maize_NatColor_final_1030.h5\",\"train_040521_maize_NatColor_final_1109.h5\", \"train_040521_maize_NatColor_final_1119.h5\",\"train_040521_maize_NatColor_final_1220.h5\"] #\"train_uavf_maize_NatColor_1109.h5\" was removed because of over exposure\n","        xx.sort()\n","        # print(xx)\n","        key_is = []\n","        for i in range(len(xx)):\n","            f_i = xx[i]\n","            h5f_i = h5py.File(f_i, 'r')\n","            keys_i = list(h5f_i.keys())\n","            keys_i.sort()\n","            key_i_n  = [\"_\".join([str(i), x]) for x in keys_i]\n","            key_is = key_is + key_i_n\n","            #print((\"key_is\", key_is))\n","            h5f_i.close()\n","        \n","        self.keys = key_is\n","        \n","    def __len__(self):\n","        return len(self.keys)\n","    def __getitem__(self, index):\n","        xx = [\"train_040521_maize_NatColor_final_1030.h5\",\"train_040521_maize_NatColor_final_1109.h5\", \"train_040521_maize_NatColor_final_1119.h5\",\"train_040521_maize_NatColor_final_1220.h5\"] #\"train_uavf_maize_NatColor_1109.h5\" was removed because of over exposure\n","        xx.sort()\n","        key = str(self.keys[index])\n","        key_path_i = key.split(\"_\")[0]\n","        key_key = key.split(\"_\")[1]\n","        h5f_a = h5py.File(xx[int(key_path_i)], 'r')\n","        #\n","        data_a = np.array(h5f_a[key_key])\n","        data = torch.as_tensor(data_a)\n","        # crop\n","        w = int(data.size()[1])\n","        h = int(data.size()[2])\n","        th, tw = self.crop_size, self.crop_size\n","        if w > tw or h > th:\n","            i = 0\n","            j = 0\n","            data = data[:,i:i+th,j:j+tw]\n","        h5f_a.close()\n","        return data[0:5,:,:], data[5:8,:,:]\n","\n","class HyperDataset_list_rice_RGB(udata.Dataset):\n","    def __init__(self, crop_size=64):\n","        self.crop_size = crop_size\n","        xx = [\"train_uavf_rice_NatColor_final_0821.h5\",\"train_uavf_rice_NatColor_final_1026.h5\",\"train_uavf_rice_NatColor_final_1124.h5\"] #\"train_uavf_rice_NatColor_final_0927.h5\" was removed due to over exposure\n","        xx.sort()\n","        # print(xx)\n","        key_is = []\n","        for i in range(len(xx)):\n","            f_i = xx[i]\n","            h5f_i = h5py.File(f_i, 'r')\n","            keys_i = list(h5f_i.keys())\n","            keys_i.sort()\n","            key_i_n  = [\"_\".join([str(i), x]) for x in keys_i]\n","            key_is = key_is + key_i_n\n","            h5f_i.close()\n","        \n","        self.keys = key_is\n","        \n","    def __len__(self):\n","        return len(self.keys)\n","    def __getitem__(self, index):\n","        xx = [\"train_uavf_rice_NatColor_final_0821.h5\",\"train_uavf_rice_NatColor_final_1026.h5\",\"train_uavf_rice_NatColor_final_1124.h5\"] #\"train_uavf_rice_NatColor_final_0927.h5\" was removed due to over exposure\n","        xx.sort()\n","        key = str(self.keys[index])\n","        key_path_i = key.split(\"_\")[0]\n","        key_key = key.split(\"_\")[1]\n","        h5f_a = h5py.File(xx[int(key_path_i)], 'r')\n","        #\n","        data_a = np.array(h5f_a[key_key])\n","        data = torch.as_tensor(data_a)\n","        # crop\n","        w = int(data.size()[1])\n","        h = int(data.size()[2])\n","        th, tw = self.crop_size, self.crop_size\n","        if w > tw or h > th:\n","            i = 0\n","            j = 0\n","            data = data[:,i:i+th,j:j+tw]\n","        h5f_a.close()\n","        return data[0:5,:,:], data[5:8,:,:]\n","\n","def batch_MRAE(im_true, im_fake):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    Itrue = im_true.clamp(0.,1.).reshape(N, C*H*W)\n","    Ifake = im_fake.clamp(0.,1.).reshape(N, C*H*W)\n","    mse = nn.MSELoss(reduction='none')\n","    err = mse(Itrue, Ifake).sqrt_().div_(Itrue).sum(dim=1, keepdim=True).div_(C*H*W)\n","    return torch.mean(err)\n","\n","def batch_RMSE(im_true, im_fake):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    Itrue = im_true.clamp(0.,1.).reshape(N, C*H*W)\n","    Ifake = im_fake.clamp(0.,1.).reshape(N, C*H*W)\n","    mse = nn.MSELoss(reduction='none')\n","    err = mse(Itrue, Ifake).sum(dim=1, keepdim=True).div_(C*H*W).sqrt_()\n","    return torch.mean(err)\n","\n","def batch_SID(im_true, im_fake):\n","    N = im_true.size()[0]\n","    C = im_true.size()[1]\n","    H = im_true.size()[2]\n","    W = im_true.size()[3]\n","    Itrue = im_true.clone().reshape(N, C, H*W)\n","    Ifake = im_fake.clone().reshape(N, C, H*W)\n","    denom1 = torch.pow(Itrue,2).sum(dim=1).sqrt_().reshape(N, H*W)\n","    denom2 = torch.pow(Ifake,2).sum(dim=1).sqrt_().reshape(N, H*W)\n","    #\n","    unit_t = torch.div(Itrue, denom1.unsqueeze(1))\n","    uint_f = torch.div(Ifake, denom2.unsqueeze(1))\n","    #\n","    sid = ((unit_t - uint_f)* (unit_t.log() - uint_f.log())).sum(dim = 1).reshape(N, H*W)\n","    sid = sid.sum() / (N*H*W)\n","    return sid\n","\n","def weights_init_kaimingNormal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.kaiming_normal_(m.weight.data, a=0.2, mode='fan_in')\n","    elif classname.find('Linear') != -1:\n","        nn.init.kaiming_normal_(m.weight.data, a=0.2, mode='fan_in')\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal(m.weight.data, 0, 0.01)\n","        nn.init.constant(m.bias.data, 0.0)\n","    elif classname.find('InstanceNorm') != -1:\n","        nn.init.normal(m.weight.data, 0, 0.01)\n","        nn.init.constant(m.bias.data, 0.0)\n","\n","## find the \"keys\"\n","h5f = h5py.File('train_uavf_maize_natlk_2_1220.h5', 'r')\n","keys = list(h5f.keys())\n","keys.sort()\n","h5f.close()"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6swvuIE-Lhm"},"source":["## process the data\n","# data_process_list_n(path=path) ## generate \"train_uavf_rice_noco_2_1124.h5\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ERfixWWgWwjh"},"source":["######   MSI reconstruction model\n","\n","class residual_block(nn.Module):\n","    def __init__(self):\n","        super(residual_block, self).__init__()\n","        self.conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.relu2 = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.relu1(out)\n","        out = self.conv2(out)\n","        out = torch.add(out,residual) \n","        out = self.relu2(out)\n","        return out\n","    \n","#####             Reconstruction_model\n","    \n","class Reconstruction_model(nn.Module):\n","    def __init__(self, block, block_num, input_channel, output_channel):\n","        super(Reconstruction_model, self).__init__()\n","\n","        self.in_channels = input_channel\n","        self.out_channels = output_channel\n","        self.input_conv = nn.Conv2d(self.in_channels, 64, kernel_size=3, stride=1, padding=1, bias=True) \n","        self.seq_res_block = self.stack_resBlock(block, block_num)\n","        self.conv = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=True)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.output_conv = nn.Conv2d(64, self.out_channels, kernel_size=3, stride=1, padding=1, bias=True)\n","        \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n=m.kernel_size[0]*m.kernel_size[1]*m.out_channels\n","                m.weight.data.normal_(0,sqrt(2./n))# the devide  2./n  carefully  \n","    def stack_resBlock(self,block,num_blocks):\n","        blocks = []\n","        for i in range(num_blocks):\n","            blocks.append(block()) # there is a () \n","        return nn.Sequential(*blocks)   \n","    def forward(self, x):\n","        out = self.input_conv(x)\n","        residual = out\n","        out = self.seq_res_block(out)\n","        out = self.conv(out)\n","        out = torch.add(out,residual)  \n","        out = self.relu(out)\n","        out = self.output_conv(out)\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w_V14DTU_2du","executionInfo":{"status":"ok","timestamp":1631678200951,"user_tz":-540,"elapsed":526,"user":{"displayName":"San Zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09693064954695030711"}}},"source":["\n","# Training \n","def train(train_data_loader, model, criterion_1, criterion_2, criterion_3, optimizer, iteration, init_lr ,epoch, w1, w2, w3):\n","\n","    losses = AverageMeter()\n","    average_MRAE = 0.\n","    average_RMSE = 0. \n","    average_SAM = 0.\n","    average_SID =0.\n","    \n","    num=len(train_data_loader)\n","    print('num.{}'.format(num))\n","    #optimizer.zero_grad()\n","    \n","    for i, (labels_gt, images_gt) in enumerate(train_data_loader):\n","    #for i in range(num):\n","        # Normalize the RGB vectors\n","        images_gt = torch.as_tensor(gen_random_scale_n(images_gt)).float().cuda(non_blocking=True) #+ torch.as_tensor(1e-8).float().cuda(async=True)\n","        images_gt = images_gt.clamp(1e-8, 1.0 - 1e-8)\n","        # put it on GPU\n","        labels_gt = torch.as_tensor(gen_random_scale_n(labels_gt)).float().cuda(non_blocking=True) #+ torch.as_tensor(1e-8).float().cuda(async=True)\n","        labels_gt = labels_gt.clamp(1e-8, 1.0 - 1e-8)\n","        #\n","        images = images_gt.cuda(non_blocking=True)\n","        #\n","        labels = labels_gt.cuda(non_blocking=True)\n","        #\n","        images = Variable(images, requires_grad=True)\n","        labels = Variable(labels, requires_grad=True)    \n","        \n","        # Decaying Learning Rate\n","        lr = init_lr \n","        iteration = iteration + 1\n","        #\n","        optimizer.zero_grad()\n","        hs_scaled = model.forward(images)\n","        hs_scaled[hs_scaled.isnan()] = 1e-8\n","        #\n","        hs_scaled = hs_scaled.clamp(1e-8, float(\"Inf\"))\n","        # remove extremes\n","        hs_scaled[labels==1e-8] = 1e-8\n","        #\n","        loss_1 = criterion_1(labels, hs_scaled)\n","        loss_2 = criterion_2(labels, hs_scaled)\n","        loss_3 = criterion_3(labels, hs_scaled)\n","        # control the contribution of each criterion through the coefficients \n","        loss = loss_1*w1 + loss_2*w2 + loss_3*w3\n","\n","        loss.backward()\n","        optimizer.step()\n","        #####\n","        MRAE = batch_MRAE(labels, hs_scaled)\n","        RMSE = batch_RMSE(labels, hs_scaled)\n","        SID = batch_SID(labels, hs_scaled)\n","        #\n","        average_MRAE    += MRAE.item()\n","        average_RMSE    += RMSE.item()\n","        average_SID    += SID.item()\n","        #\n","        losses.update(loss.item())\n","    return losses.avg, average_MRAE/num, average_RMSE/num, average_SID/num, iteration, lr\n","\n","# Validation\n","\n","def validate(val_loader, model, criterion_1, criterion_2, criterion_3, epoch, w1, w2, w3):\n","    \n","    model.eval()\n","    losses = AverageMeter()\n","    xxx=0\n","    num = len(val_loader)\n","    \n","    average_MRAE    =0.\n","    average_RMSE    =0.\n","    average_SAM    =0.\n","    average_SID    =0.\n","    \n","    for i, (target_gt, input_gt) in enumerate(val_loader):\n","        # Normalize the RGB vectors\n","        input_gt = torch.as_tensor(gen_random_scale_n(input_gt)).float().cuda(non_blocking=True) #+ torch.as_tensor(1e-8).float().cuda(async=True)\n","        input_gt = input_gt.clamp(1e-8, 1.0 - 1e-8)\n","\n","        input = input_gt.cuda(non_blocking=True)\n","        target = torch.as_tensor(gen_random_scale_n(target_gt)).float().cuda(non_blocking=True) #+ torch.as_tensor(1e-8).float().cuda(async=True)\n","        target = target.clamp(1e-8, 1.0 - 1e-8)\n","        #\n","        target = target.cuda(non_blocking=True)\n","        #\n","        input_var = torch.autograd.Variable(input)\n","        target_var = torch.autograd.Variable(target)\n","    \n","        # compute hs\n","        with torch.no_grad():\n","            hs_scaled = model.forward(input_var)\n","        hs_scaled[hs_scaled.isnan()] = 1e-8\n","        hs_scaled = hs_scaled.clamp(1e-8, float(\"Inf\"))\n","        # remove extremes\n","        hs_scaled[target_var==1e-8] = 1e-8\n","        #\n","        #\n","        loss_1 = criterion_1(target_var, hs_scaled)\n","        loss_2 = criterion_2(target_var, hs_scaled)\n","        loss_3 = criterion_3(target_var, hs_scaled)\n","        # control the contribution of each criterion through the coefficients \n","        loss = loss_1*w1 + loss_2*w2 + loss_3*w3\n","        #####\n","        MRAE = batch_MRAE(target_var, hs_scaled)\n","        RMSE = batch_RMSE(target_var, hs_scaled)\n","        SID = batch_SID(target_var, hs_scaled)\n","        #\n","        average_MRAE    += MRAE.item()\n","        average_RMSE    += RMSE.item()\n","        average_SID    += SID.item()\n","        #####\n","        ## generate a figure compare the reconstructed spectra and ground truth, every epoch\n","        if epoch%1==0:\n","            #print(i)\n","            if (i+1)%10==0:\n","                xxx += 1\n","                H = target_var.size()[2]\n","                W = target_var.size()[3]\n","                real_spectrum = target_var.data.cpu().numpy()[0,:,int(H/2),int(W/2)]\n","                fake_spectrum = hs_scaled.data.cpu().numpy()[0,:,int(H/2),int(W/2)]\n","                I_spectrum = plot_spectrum_msi(real_spectrum, fake_spectrum, \"val_\"+str(epoch),i)\n","                ##\n","                input_gt_plot = input_gt[0,:,:,:].squeeze().permute(1,2,0).data.cpu().numpy()\n","                fig, axis = plotwithcolorbar(input_gt_plot, \"fake image\" )\n","                fig.savefig(os.path.join(iteration_path, \"{}_test_fake_img_{}.png\".format(epoch,i)))\n","                ##\n","                print(\"val_num: \" + str(xxx))\n","        #  record loss\n","        losses.update(loss.item())\n","    return losses.avg, average_MRAE/num, average_RMSE/num, average_SID/num\n","\n"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"uwHaRKj403l7"},"source":["###               spectral reconstruction model \n","\n","# the coefficients, whether 0 or >0 to decide whether single or composite loss functions to be used\n","# the coefficients determine the contribution of each loss function to the final loss\n","w1 = 0 # mrae_loss\n","w2 = 1 # mse_loss\n","w3 = 0 # sid_loss\n","# number of residual blocks, should be tuned to find the optimal number\n","num_resBlock = 3\n","# decide which loss function to use\n","criterion_1 = mrae_loss\n","criterion_2 = nn.MSELoss()\n","criterion_3 = sid_loss \n","#\n","# \n","epoch_total = 10000\n","init_lr = 1e-3\n","#\n","cudnn.benchmark = True\n","## input and output image channels\n","rgb_channels = 3\n","msi_channels = 5\n","## load dataset\n","print(\"\\nloading dataset ...\\n\")\n","#\n","trainDataset = HyperDataset_list_maize_RGB(crop_size=600)  ## here not the training data but the whole data set for this work\n","\n","# set the ratio of training and validation set\n","validation_split = (1/3)\n","\n","dataset_len = len(trainDataset) #trainDataset\n","indices = list(range(dataset_len))\n","\n","# Randomly splitting indices:\n","val_len = int(np.ceil(validation_split * dataset_len))\n","validation_idx = np.random.choice(indices, size=val_len, replace=False)\n","train_idx = list(set(indices) - set(validation_idx))\n","\n","## Defining the samplers for each phase based on the random indices:\n","train_sampler = SubsetRandomSampler(train_idx)\n","validation_sampler = SubsetRandomSampler(validation_idx)\n","\n","# Data Loader (Input Pipeline)\n","train_data_loader = DataLoader(dataset=trainDataset,\n","                                sampler=train_sampler,\n","                                num_workers=1,  \n","                                batch_size=1,\n","                                shuffle=False,\n","                                pin_memory=True)\n","\n","val_loader = DataLoader(dataset=trainDataset,\n","                        sampler=validation_sampler,\n","                        num_workers=1, \n","                        batch_size=1,\n","                        shuffle=False,\n","                        pin_memory=True)\n","# model assembly               \n","model = Reconstruction_model(residual_block, num_resBlock, rgb_channels, msi_channels)\n","# apply kaiming normal initialization\n","model.apply(weights_init_kaimingNormal)\n","# check whether it is possible to do multi-GPU processing\n","if torch.cuda.device_count() > 1:\n","    model = nn.DataParallel(model)\n","if torch.cuda.is_available():\n","    model.cuda()\n","\n","iteration = 0\n","\n","## set the original values for the evaluation\n","#\n","record_ts_loss= np.inf\n","record_ts_MRAE = np.inf\n","record_ts_RMSE = np.inf\n","record_ts_SID = np.inf \n","#\n","iteration_folder = \"UAV_Maize_specReconsruction_w1-{}_w2-{}_w3-{}\".format(w1, w2, w3)\n","model_folder = \"UAV_Maize_specReconsruction_w1-{}_w2-{}_w3-{}\".format(w1, w2, w3)\n","#\n","iteration_path = os.path.join(os.getcwd(), iteration_folder)\n","if not os.path.exists(iteration_path):\n","    os.makedirs(iteration_path)\n","\n","optimizer=torch.optim.Adamax(model.parameters(), lr=init_lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)\n","\n","model_path = os.path.join(os.getcwd(), model_folder)\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","loss_csv = open(os.path.join(model_path, 'w123_{}_{}_{}_loss.csv'.format(w1,w2,w3)), 'w+')\n","\n","log_dir = os.path.join(model_path,'w123_{}_{}_{}_train.log'.format(w1,w2,w3))\n","logger = initialize_logger(log_dir)\n","\n","# load the trained model if there is any or put \"\" instead\n","resume_file = \"\" #os.path.join(model_path, \"MSIs_reconstruction_trained.pkl\") #\"\" # can be specified if there is already trained model \n","if resume_file:\n","    print(\"=> loading checkpoint '{}'\".format(resume_file))\n","    checkpoint = torch.load(resume_file)\n","    start_epoch = checkpoint['epoch']\n","    iteration = checkpoint['iter']\n","    model.load_state_dict(checkpoint['state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer'])\n","    \n","for epoch in range(epoch_total): ## specify the number of epochs to run\n","    start_time = time.time()         \n","    tr_loss, tr_MRAE, tr_RMSE, tr_SID, iteration, lr = train(train_data_loader, model, criterion_1, criterion_2, criterion_3, optimizer, iteration, init_lr, epoch, w1,w2,w3)\n","    #\n","    # here to implement constant learning rate\n","    end_time = time.time() # only record the training time\n","    epoch_time = end_time - start_time\n","    print(datetime.datetime.now())\n","    #lr=init_lr\n","    ts_loss, ts_MRAE, ts_RMSE, ts_SID = validate(val_loader, model, criterion_1, criterion_2, criterion_3, epoch, w1,w2,w3)\n","    #\n","    # Save model\n","    ########################### on maize validation\n","    # (1) ts_loss evaluation\n","    print(\"old_ts_loss\", record_ts_loss, \"old_ts_MRAE\", record_ts_MRAE, \"old_ts_RMSE\",record_ts_RMSE, \"old_ts_SID\",record_ts_SID)\n","    # because weight is not added to validation loss, will save any model with lower loss rather than any individual loss\n","    if ts_loss < record_ts_loss: #and ts_MRAE < record_ts_MRAE or ts_loss < record_ts_loss and ts_SID < record_ts_SID \n","        record_ts_loss = ts_loss\n","        save_checkpoint_sp(model_path, epoch, iteration, model, optimizer, \"ts_loss\")\n","        record_ts_MRAE = ts_MRAE\n","        record_ts_RMSE = ts_RMSE\n","        record_ts_SID = ts_SID\n","\n","        print(\"ts_loss\")\n","        print(\"updated_ts_loss\", record_ts_loss,\"updated_ts_MRAE\", record_ts_MRAE, \"updated_ts_RMSE\",record_ts_RMSE, \"updated_ts_SID\",record_ts_SID)\n","    \n","    # print loss \n","    print (\"Epoch:{}, Iter:{}, Time:{}, learning rate:{}, Train loss:{}, Train MRAE:{}, Train RMSE:{}, Train SID:{}\".format(\n","        epoch, iteration, epoch_time, lr, tr_loss, tr_MRAE, tr_RMSE, tr_SID))\n","    # \n","    logger.info(\"Epoch{}, Iter{}, Time:{}, learning rate:{}, Train loss:{},Train MRAE:{},Train RMSE:{}, Train SID:{}, Test loss:{},Test MRAE:{},Test RMSE:{}, Test SID:{}\".format(\n","        epoch, iteration, epoch_time, lr, tr_loss, tr_MRAE,tr_RMSE, tr_SID, ts_loss, ts_MRAE,ts_RMSE, ts_SID))\n","\n","    ###\n","    print(\"w1: {}, w2: {}, w3: {}\".format(w1,w2,w3))\n","    if (epoch+2)%5 ==0:\n","        init_lr = init_lr*0.8\n","        print((\"updated learning rate\", init_lr))"],"execution_count":null,"outputs":[]}]}